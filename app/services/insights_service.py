from typing import List, Optional, Dict, Any
from uuid import UUID
from app.core.database import get_supabase, get_supabase_service
from app.models.insight import InsightCreate, InsightUpdate, InsightResponse, InsightListResponse
from app.models.insight_chunk import InsightChunkCreate, ChunkingResult
from app.services.embedding_service import generate_chunk_embeddings, is_embedding_enabled
from app.services.insight_tag_service import InsightTagService
from app.utils.metadata import fetch_page_content
import logging
import os
from copy import deepcopy
import asyncio
from app.utils.summarize import generate_summary
from datetime import datetime, date
import re
import hashlib
import json
from functools import lru_cache
import time

logger = logging.getLogger(__name__)

# ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œç”¨äºå‡å°‘é‡å¤æŸ¥è¯¢
_query_cache = {}
_cache_ttl = 30  # 30ç§’ç¼“å­˜

def _cache_key(func_name: str, *args, **kwargs) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_parts = [func_name] + [str(arg) for arg in args] + [f"{k}={v}" for k, v in sorted(kwargs.items())]
    return hashlib.md5("|".join(key_parts).encode()).hexdigest()

def _get_cache(key: str):
    """è·å–ç¼“å­˜"""
    if key in _query_cache:
        cached_data, timestamp = _query_cache[key]
        if time.time() - timestamp < _cache_ttl:
            return cached_data
        else:
            del _query_cache[key]
    return None

def _set_cache(key: str, data):
    """è®¾ç½®ç¼“å­˜"""
    _query_cache[key] = (data, time.time())
    # ç®€å•çš„ç¼“å­˜æ¸…ç†ï¼šä¿æŒæœ€å¤š100ä¸ªç¼“å­˜é¡¹
    if len(_query_cache) > 100:
        oldest_key = min(_query_cache.keys(), key=lambda k: _query_cache[k][1])
        del _query_cache[oldest_key]

class InsightsService:
    """InsightsæœåŠ¡ç±»"""
    
    @staticmethod
    async def get_insights(
        user_id: UUID,
        page: int = 1,
        limit: int = 10,
        search: Optional[str] = None,
        target_user_id: Optional[UUID] = None,
        stack_id: Optional[int] = None,
        include_tags: bool = False
    ) -> Dict[str, Any]:
        """è·å–insightsåˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰"""
        try:
            supabase = get_supabase()
            supabase_service = get_supabase_service()
            
            # ç¡®å®šè¦æŸ¥è¯¢çš„ç”¨æˆ·ID - å¦‚æœæ²¡æœ‰æŒ‡å®štarget_user_idï¼Œé»˜è®¤æŸ¥è¯¢å½“å‰ç”¨æˆ·
            query_user_id = str(target_user_id) if target_user_id else str(user_id)
            
            # æƒé™æ£€æŸ¥ï¼šå¦‚æœæŒ‡å®šäº†target_user_idï¼ŒéªŒè¯æ˜¯å¦ä¸ºå½“å‰ç”¨æˆ·
            # å¦‚æœæ²¡æœ‰æŒ‡å®štarget_user_idï¼Œåˆ™æŸ¥è¯¢å½“å‰ç”¨æˆ·çš„insightsï¼ˆè¿™æ˜¯å®‰å…¨çš„ï¼‰
            if target_user_id and str(target_user_id) != str(user_id):
                logger.warning(f"ç”¨æˆ· {user_id} å°è¯•è®¿é—®ç”¨æˆ· {target_user_id} çš„insights")
                return {
                    "success": False,
                    "message": "åªèƒ½æŸ¥çœ‹è‡ªå·±çš„insights"
                }
            
            logger.info(f"æŸ¥è¯¢ç”¨æˆ· {query_user_id} çš„insightsï¼Œå½“å‰ç”¨æˆ·: {user_id}, stack_id: {stack_id}")
            
            # æ„å»ºæŸ¥è¯¢ - åŒ…å«JSONB tagså­—æ®µå’Œstack_idï¼Œå®ç°é›¶JOINæŸ¥è¯¢
            query = supabase.table('insights').select(
                'id, title, description, url, image_url, created_at, updated_at, tags, stack_id'
            ).eq('user_id', query_user_id)
            
            # æ·»åŠ stack_idç­›é€‰æ¡ä»¶
            if stack_id is not None:
                query = query.eq('stack_id', stack_id)
                logger.info(f"ğŸ” æ·»åŠ stack_idç­›é€‰: {stack_id}")
            
            # æ·»åŠ æœç´¢æ¡ä»¶
            if search:
                query = query.or_(f'title.ilike.%{search}%,description.ilike.%{search}%')
            
            # æ·»åŠ æ’åºå’Œåˆ†é¡µ
            query = query.order('created_at', desc=True).range((page - 1) * limit, page * limit - 1)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response = query.execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"è·å–insightså¤±è´¥: {response.error}")
                return {"success": False, "message": "è·å–insightså¤±è´¥"}
            
            insights = response.data or []
            logger.info(f"æˆåŠŸè·å– {len(insights)} æ¡insights")
            
            # è·å–æ€»æ•°
            count_query = supabase.table('insights').select('id', count='exact').eq('user_id', query_user_id)
            if stack_id is not None:
                count_query = count_query.eq('stack_id', stack_id)
            if search:
                count_query = count_query.or_(f'title.ilike.%{search}%,description.ilike.%{search}%')
            
            count_response = count_query.execute()
            total = count_response.count if hasattr(count_response, 'count') else len(insights)
            
            # ğŸš€ è¶…çº§ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨JSONB tagså­—æ®µï¼Œé›¶JOINæŸ¥è¯¢ï¼
            insight_responses = []
            for insight in insights:
                # ç›´æ¥ä»JSONBå­—æ®µè·å–æ ‡ç­¾ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
                jsonb_tags = insight.get('tags', [])
                
                # å¦‚æœJSONB tagsä¸ºç©ºï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢æ–¹å¼ï¼ˆå…¼å®¹æ€§ï¼‰
                if not jsonb_tags:
                    # è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦å›é€€åˆ°JOINæŸ¥è¯¢ï¼Œç›®å‰å…ˆè¿”å›ç©ºæ•°ç»„
                    insight_tags = []
                else:
                    # ç›´æ¥ä½¿ç”¨JSONBæ•°æ®ï¼Œæ€§èƒ½æœ€ä¼˜
                    insight_tags = jsonb_tags if isinstance(jsonb_tags, list) else []
                
                insight_response = {
                    "id": insight['id'],
                    "user_id": query_user_id,  # ç›´æ¥ä½¿ç”¨æŸ¥è¯¢çš„ user_id
                    "title": insight['title'],
                    "description": insight['description'],
                    "url": insight.get('url'),
                    "image_url": insight.get('image_url'),
                    "created_at": insight['created_at'],
                    "updated_at": insight['updated_at'],
                    "stack_id": insight.get('stack_id'),  # åŒ…å«stack_idå­—æ®µ
                    "tags": insight_tags  # ğŸš€ é›¶å»¶è¿Ÿæ ‡ç­¾æ•°æ®ï¼
                }
                insight_responses.append(insight_response)
            
            return {
                "success": True,
                "data": {
                    "insights": insight_responses,
                    "pagination": {
                        "page": page,
                        "limit": limit,
                        "total": total,
                        "total_pages": (total + limit - 1) // limit
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–insightså¤±è´¥: {str(e)}")
            return {"success": False, "message": f"è·å–insightså¤±è´¥: {str(e)}"}
    
    @staticmethod
    async def get_all_user_insights(
        user_id: UUID,
        search: Optional[str] = None,
        target_user_id: Optional[UUID] = None
    ) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æ‰€æœ‰insightsï¼ˆä¸åˆ†é¡µï¼‰"""
        try:
            supabase = get_supabase()
            
            # ç¡®å®šè¦æŸ¥è¯¢çš„ç”¨æˆ·ID - å¦‚æœæ²¡æœ‰æŒ‡å®štarget_user_idï¼Œé»˜è®¤æŸ¥è¯¢å½“å‰ç”¨æˆ·
            query_user_id = str(target_user_id) if target_user_id else str(user_id)
            
            # æƒé™æ£€æŸ¥ï¼šå¦‚æœæŒ‡å®šäº†target_user_idï¼ŒéªŒè¯æ˜¯å¦ä¸ºå½“å‰ç”¨æˆ·
            # å¦‚æœæ²¡æœ‰æŒ‡å®štarget_user_idï¼Œåˆ™æŸ¥è¯¢å½“å‰ç”¨æˆ·çš„insightsï¼ˆè¿™æ˜¯å®‰å…¨çš„ï¼‰
            if target_user_id and str(target_user_id) != str(user_id):
                logger.warning(f"ç”¨æˆ· {user_id} å°è¯•è®¿é—®ç”¨æˆ· {target_user_id} çš„insights")
                return {
                    "success": False,
                    "message": "åªèƒ½æŸ¥çœ‹è‡ªå·±çš„insights"
                }
            
            logger.info(f"æŸ¥è¯¢ç”¨æˆ· {query_user_id} çš„æ‰€æœ‰insightsï¼Œå½“å‰ç”¨æˆ·: {user_id}")
            
            # æ„å»ºæŸ¥è¯¢ - åŒ…å«JSONB tagså­—æ®µå’Œstack_idï¼Œå®ç°é›¶JOINæŸ¥è¯¢
            query = supabase.table('insights').select(
                'id, title, description, url, image_url, created_at, updated_at, tags, stack_id'
            ).eq('user_id', query_user_id)
            
            # æ·»åŠ æœç´¢æ¡ä»¶
            if search:
                query = query.or_(f'title.ilike.%{search}%,description.ilike.%{search}%')
            
            # æ·»åŠ æ’åºå’Œé™åˆ¶ï¼ˆé¿å…ä¸€æ¬¡æ€§è·å–è¿‡å¤šæ•°æ®ï¼‰
            query = query.order('created_at', desc=True)
            
            # æ€§èƒ½ä¿æŠ¤ï¼šå¦‚æœæ˜¯è·å–æ‰€æœ‰æ•°æ®ï¼Œé™åˆ¶æœ€å¤§æ•°é‡
            MAX_INSIGHTS_LIMIT = int(os.getenv('MAX_INSIGHTS_LIMIT', '1000'))
            query = query.limit(MAX_INSIGHTS_LIMIT)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response = query.execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"è·å–æ‰€æœ‰insightså¤±è´¥: {response.error}")
                return {"success": False, "message": "è·å–æ‰€æœ‰insightså¤±è´¥"}
            
            insights = response.data or []
            logger.info(f"æˆåŠŸè·å– {len(insights)} æ¡insights")
            
            # ä¼˜åŒ–ï¼šå¦‚æœ insights æ•°é‡å¾ˆå¤§ï¼Œè€ƒè™‘åˆ†æ‰¹å¤„ç†æ ‡ç­¾
            if len(insights) > 100:
                logger.warning(f"ç”¨æˆ· {query_user_id} æœ‰å¤§é‡ insights ({len(insights)})ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
            
            # ğŸš€ è¶…çº§ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨JSONB tagså­—æ®µï¼Œé›¶JOINæŸ¥è¯¢ï¼
            insight_responses = []
            for insight in insights:
                # ç›´æ¥ä»JSONBå­—æ®µè·å–æ ‡ç­¾ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
                jsonb_tags = insight.get('tags', [])
                
                # å¦‚æœJSONB tagsä¸ºç©ºï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢æ–¹å¼ï¼ˆå…¼å®¹æ€§ï¼‰
                if not jsonb_tags:
                    # è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦å›é€€åˆ°JOINæŸ¥è¯¢ï¼Œç›®å‰å…ˆè¿”å›ç©ºæ•°ç»„
                    insight_tags = []
                else:
                    # ç›´æ¥ä½¿ç”¨JSONBæ•°æ®ï¼Œæ€§èƒ½æœ€ä¼˜
                    insight_tags = jsonb_tags if isinstance(jsonb_tags, list) else []
                
                insight_response = {
                    "id": insight['id'],
                    "user_id": query_user_id,  # ç›´æ¥ä½¿ç”¨æŸ¥è¯¢çš„ user_idï¼Œé¿å…é‡å¤è½¬æ¢
                    "title": insight['title'],
                    "description": insight['description'],
                    "url": insight.get('url'),
                    "image_url": insight.get('image_url'),
                    "created_at": insight['created_at'],
                    "updated_at": insight['updated_at'],
                    "stack_id": insight.get('stack_id'),  # åŒ…å«stack_idå­—æ®µ
                    "tags": insight_tags  # ğŸš€ é›¶å»¶è¿Ÿæ ‡ç­¾æ•°æ®ï¼
                }
                insight_responses.append(insight_response)
            
            return {
                "success": True,
                "data": {
                    "insights": insight_responses
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–æ‰€æœ‰insightså¤±è´¥: {str(e)}")
            return {"success": False, "message": f"è·å–æ‰€æœ‰insightså¤±è´¥: {str(e)}"}
    
    @staticmethod
    async def get_insights_incremental(
        user_id: UUID,
        since: Optional[str] = None,
        etag: Optional[str] = None,
        limit: int = 50
    ) -> Dict[str, Any]:
        """å¢é‡è·å–ç”¨æˆ·insightsï¼ˆåªè¿”å›å˜åŠ¨çš„æ•°æ®ï¼‰- æ–°æ¥å£"""
        try:
            supabase = get_supabase()
            
            logger.info(f"å¢é‡æŸ¥è¯¢ç”¨æˆ· {user_id} çš„insightsï¼Œsince={since}, etag={etag}")
            
            # æ„å»ºåŸºç¡€æŸ¥è¯¢ - åŒ…å«JSONB tagså­—æ®µï¼Œå®ç°é›¶JOINæŸ¥è¯¢
            query = supabase.table('insights').select(
                'id, title, description, url, image_url, created_at, updated_at, tags'
            ).eq('user_id', str(user_id))
            
            # æ—¶é—´è¿‡æ»¤ï¼šåªè·å–æŒ‡å®šæ—¶é—´ä¹‹åçš„æ•°æ®
            if since:
                try:
                    # è§£ææ—¶é—´æˆ³ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                    if since.endswith('Z'):
                        since_dt = datetime.fromisoformat(since.replace('Z', '+00:00'))
                    else:
                        since_dt = datetime.fromisoformat(since)
                    
                    query = query.gte('updated_at', since_dt.isoformat())
                    logger.info(f"è¿‡æ»¤æ—¶é—´: {since_dt}")
                except Exception as time_err:
                    logger.warning(f"æ—¶é—´æ ¼å¼è§£æå¤±è´¥: {time_err}")
                    return {"success": False, "message": "æ—¶é—´æ ¼å¼é”™è¯¯"}
            
            # æ·»åŠ æ’åºå’Œé™åˆ¶
            query = query.order('updated_at', desc=True).limit(limit)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response = query.execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"å¢é‡è·å–insightså¤±è´¥: {response.error}")
                return {"success": False, "message": "å¢é‡è·å–insightså¤±è´¥"}
            
            insights = response.data or []
            logger.info(f"å¢é‡æŸ¥è¯¢è·å– {len(insights)} æ¡insights")
            
            # ç”Ÿæˆæ•°æ®æŒ‡çº¹ç”¨äº ETag ç¼“å­˜
            data_hash = _generate_etag(insights)
            
            # ETag æ£€æŸ¥ï¼šå¦‚æœæ•°æ®æ²¡æœ‰å˜åŒ–ï¼Œè¿”å› 304
            if etag and etag == data_hash and insights:
                logger.info("æ•°æ®æœªå˜åŒ–ï¼Œè¿”å› 304 Not Modified")
                return {
                    "success": True,
                    "not_modified": True,
                    "etag": data_hash
                }
            
            # ğŸš€ è¶…çº§ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨JSONB tagså­—æ®µï¼Œé›¶JOINæŸ¥è¯¢ï¼
            insight_responses = []
            for insight in insights:
                # ç›´æ¥ä»JSONBå­—æ®µè·å–æ ‡ç­¾ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
                jsonb_tags = insight.get('tags', [])
                
                # å¦‚æœJSONB tagsä¸ºç©ºï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢æ–¹å¼ï¼ˆå…¼å®¹æ€§ï¼‰
                if not jsonb_tags:
                    # è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦å›é€€åˆ°JOINæŸ¥è¯¢ï¼Œç›®å‰å…ˆè¿”å›ç©ºæ•°ç»„
                    insight_tags = []
                else:
                    # ç›´æ¥ä½¿ç”¨JSONBæ•°æ®ï¼Œæ€§èƒ½æœ€ä¼˜
                    insight_tags = jsonb_tags if isinstance(jsonb_tags, list) else []
                
                insight_response = {
                    "id": insight['id'],
                    "user_id": str(user_id),
                    "title": insight['title'],
                    "description": insight['description'],
                    "url": insight.get('url'),
                    "image_url": insight.get('image_url'),
                    "created_at": insight['created_at'],
                    "updated_at": insight['updated_at'],
                    "tags": insight_tags  # ğŸš€ é›¶å»¶è¿Ÿæ ‡ç­¾æ•°æ®ï¼
                }
                insight_responses.append(insight_response)
            
            # è®¡ç®—æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
            has_more = len(insights) >= limit
            last_updated = insights[0]['updated_at'] if insights else datetime.utcnow().isoformat()
            
            return {
                "success": True,
                "data": {
                    "insights": insight_responses,
                    "has_more": has_more,
                    "last_updated": last_updated,
                    "etag": data_hash,
                    "count": len(insight_responses)
                }
            }
            
        except Exception as e:
            logger.error(f"å¢é‡è·å–insightså¤±è´¥: {str(e)}")
            return {"success": False, "message": f"å¢é‡è·å–insightså¤±è´¥: {str(e)}"}
    
    @staticmethod
    async def get_insight(insight_id: UUID, user_id: UUID) -> Dict[str, Any]:
        """è·å–å•ä¸ªinsightè¯¦æƒ…"""
        try:
            supabase = get_supabase()
            
            # è·å–insight
            response = supabase.table('insights').select('*').eq('id', str(insight_id)).execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"è·å–insightå¤±è´¥: {response.error}")
                return {"success": False, "message": "è·å–insightå¤±è´¥"}
            
            if not response.data:
                return {"success": False, "message": "Insightä¸å­˜åœ¨"}
            
            insight = response.data[0]
            
            # æƒé™æ£€æŸ¥ï¼šåªèƒ½æŸ¥çœ‹è‡ªå·±çš„insight
            if insight['user_id'] != str(user_id):
                return {"success": False, "message": "æ— æƒæŸ¥çœ‹æ­¤insight"}
            
            # è·å–æ ‡ç­¾
            tags_result = await InsightTagService.get_insight_tags(insight_id, user_id)
            insight_tags = tags_result.get('data', []) if tags_result.get('success') else []
            
            # æ„å»ºå“åº”æ•°æ®
            insight_response = InsightResponse(
                id=UUID(insight['id']),
                user_id=UUID(insight['user_id']),
                title=insight['title'],
                description=insight['description'],
                url=insight.get('url'),
                image_url=insight.get('image_url'),
                meta=insight.get('meta'),
                created_at=insight['created_at'],
                updated_at=insight['updated_at'],
                tags=insight_tags
            )
            
            return {"success": True, "data": insight_response}
            
        except Exception as e:
            logger.error(f"è·å–insightå¤±è´¥: {str(e)}")
            return {"success": False, "message": f"è·å–insightå¤±è´¥: {str(e)}"}
    
    @staticmethod
    async def create_insight(insight_data: InsightCreate, user_id: UUID) -> Dict[str, Any]:
        """åˆ›å»ºæ–°insight"""
        try:
            supabase = get_supabase()
            supabase_service = get_supabase_service()
            
            # å‡†å¤‡insightæ•°æ®ï¼ˆä¸åŒ…å«thoughtï¼Œå·²è¿ç§»åˆ°insight_contentsï¼‰
            insight_insert_data = {
                'title': insight_data.title,
                'description': insight_data.description,
                'url': insight_data.url,
                'image_url': insight_data.image_url,
                'user_id': str(user_id),
                'tags': [],  # æ–°çš„JSONBå­—æ®µï¼Œåˆå§‹ä¸ºç©ºæ•°ç»„
                'stack_id': insight_data.stack_id  # æ·»åŠ stack_idæ”¯æŒ
                # æ³¨æ„ï¼šthoughtå­—æ®µå·²è¿ç§»åˆ°insight_contentsè¡¨
            }
            
            # è°ƒè¯•æ—¥å¿—
            logger.info(f"ğŸ” DEBUG: å‡†å¤‡æ’å…¥insightæ•°æ®: stack_id={insight_data.stack_id}, type={type(insight_data.stack_id)}")
            logger.info(f"ğŸ” DEBUG: å®Œæ•´insight_insert_data: {insight_insert_data}")
            
            # ç¡®ä¿stack_idè¢«åŒ…å«åœ¨æ’å…¥æ•°æ®ä¸­ï¼Œå³ä½¿ä¸ºNone
            if 'stack_id' not in insight_insert_data:
                insight_insert_data['stack_id'] = insight_data.stack_id
                logger.info(f"ğŸ” DEBUG: æ‰‹åŠ¨æ·»åŠ stack_idåˆ°æ’å…¥æ•°æ®: {insight_insert_data['stack_id']}")
            
            # éªŒè¯stack_idå­—æ®µ
            if insight_insert_data.get('stack_id') is not None:
                logger.info(f"ğŸ” DEBUG: stack_idå°†è¢«æ’å…¥: {insight_insert_data['stack_id']} (type: {type(insight_insert_data['stack_id'])})")
            else:
                logger.warning(f"ğŸ” DEBUG: stack_idä¸ºNoneï¼Œå°†æ’å…¥NULLå€¼")

            # å¯é€‰å†™å…¥ metaï¼ˆå¦‚åˆ—å­˜åœ¨ï¼‰ï¼Œä»¥ JSON å½¢å¼å­˜å‚¨ç½‘é¡µå…ƒæ•°æ®
            try:
                if hasattr(insight_data, 'meta') and isinstance(getattr(insight_data, 'meta'), dict):
                    insight_insert_data['meta'] = getattr(insight_data, 'meta')
            except Exception:
                pass
            
            # åˆ›å»ºinsightï¼ˆä½¿ç”¨ service role ä»¥é¿å… RLS é€ æˆçš„æ’å…¥å¤±è´¥ï¼‰
            logger.info(f"ğŸ” DEBUG: å‡†å¤‡åˆ›å»º insightï¼šuser_id={user_id}, url={insight_data.url}")
            logger.info(f"ğŸ” DEBUG: æœ€ç»ˆæ’å…¥æ•°æ®: {insight_insert_data}")
            response = supabase_service.table('insights').insert(insight_insert_data).execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"åˆ›å»ºinsightå¤±è´¥: {response.error}")
                return {"success": False, "message": "åˆ›å»ºinsightå¤±è´¥"}
            
            if not response.data:
                return {"success": False, "message": "åˆ›å»ºinsightå¤±è´¥"}
            
            insight = response.data[0]
            logger.info(f"ğŸ” DEBUG: insight åˆ›å»ºæˆåŠŸ: id={insight.get('id')}, user_id={insight.get('user_id')}")
            logger.info(f"ğŸ” DEBUG: åˆ›å»ºçš„insightæ•°æ®: {insight}")
            logger.info(f"ğŸ” DEBUG: åˆ›å»ºçš„insight stack_id: {insight.get('stack_id')} (type: {type(insight.get('stack_id'))})")
            insight_id = UUID(insight['id'])

            # å¯åŠ¨å¼‚æ­¥åå°ä»»åŠ¡å¤„ç†å†…å®¹æŠ“å–å’Œæ‘˜è¦ç”Ÿæˆ
            if os.getenv('FETCH_PAGE_CONTENT_ENABLED', '').lower() in ('1', 'true', 'yes'):
                try:
                    import asyncio
                    # åˆ›å»ºåå°ä»»åŠ¡ï¼Œä¸ç­‰å¾…å®Œæˆ
                    asyncio.create_task(InsightsService._fetch_and_save_content(
                        insight_id=insight_id,
                        user_id=user_id,
                        url=insight_data.url,
                        thought=insight_data.thought  # ä¼ é€’thoughtå­—æ®µåˆ°åå°ä»»åŠ¡
                    ))
                    logger.info("å·²å¯åŠ¨å¼‚æ­¥å†…å®¹å¤„ç† pipeline åå°ä»»åŠ¡")
                except Exception as task_err:
                    logger.warning(f"å¯åŠ¨å¼‚æ­¥å†…å®¹å¤„ç†ä»»åŠ¡å¤±è´¥: {task_err}")
            else:
                logger.info("FETCH_PAGE_CONTENT_ENABLED æœªå¼€å¯ï¼Œè·³è¿‡å…¨æ–‡æŠ“å–ä¸ä¿å­˜")
            
            # å¤„ç†æ ‡ç­¾
            if insight_data.tag_ids:
                tags_result = await InsightTagService.update_insight_tags_by_ids(
                    insight_id, insight_data.tag_ids, user_id
                )
                if not tags_result.get('success'):
                    logger.warning(f"åˆ›å»ºinsightæˆåŠŸï¼Œä½†æ ‡ç­¾å¤„ç†å¤±è´¥: {tags_result.get('message')}")
            
            # è·å–å®Œæ•´çš„insightæ•°æ®ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰
            # ä½¿ç”¨ service role æ¥é¿å… RLS æƒé™é—®é¢˜
            try:
                response = supabase_service.table('insights').select('*').eq('id', str(insight_id)).execute()
                
                if not response.data:
                    logger.warning(f"åˆšåˆ›å»ºçš„insight {insight_id} æ— æ³•ç«‹å³æŸ¥è¯¢åˆ°ï¼Œå¯èƒ½æ˜¯æ•°æ®åº“å»¶è¿Ÿ")
                    # è¿”å›åŸºç¡€åˆ›å»ºæˆåŠŸä¿¡æ¯
                    return {
                        "success": True,
                        "message": "Insightåˆ›å»ºæˆåŠŸ",
                        "data": {
                            "id": str(insight_id),
                            "user_id": str(user_id),
                            "title": insight_data.title,
                            "description": insight_data.description,
                            "url": insight_data.url,
                            "image_url": insight_data.image_url,
                            "stack_id": insight_data.stack_id,
                            "tags": []
                        }
                    }
                
                insight_detail = response.data[0]
                
                # è·å–æ ‡ç­¾
                tags_result = await InsightTagService.get_insight_tags(insight_id, user_id)
                insight_tags = tags_result.get('data', []) if tags_result.get('success') else []
                
                # æ„å»ºå“åº”æ•°æ®
                return {
                    "success": True,
                    "message": "Insightåˆ›å»ºæˆåŠŸ",
                    "data": {
                        "id": insight_detail['id'],
                        "user_id": insight_detail['user_id'],
                        "title": insight_detail['title'],
                        "description": insight_detail['description'],
                        "url": insight_detail.get('url'),
                        "image_url": insight_detail.get('image_url'),
                        "stack_id": insight_detail.get('stack_id'),
                        "meta": insight_detail.get('meta'),
                        "created_at": insight_detail['created_at'],
                        "updated_at": insight_detail['updated_at'],
                        "tags": insight_tags
                    }
                }
                
            except Exception as get_error:
                logger.error(f"è·å–åˆšåˆ›å»ºçš„insightå¤±è´¥: {get_error}")
                # å³ä½¿è·å–å¤±è´¥ï¼Œä¹Ÿè¿”å›åˆ›å»ºæˆåŠŸä¿¡æ¯
                return {
                    "success": True,
                    "message": "Insightåˆ›å»ºæˆåŠŸï¼ˆè¯¦æƒ…è·å–å¤±è´¥ï¼‰",
                    "data": {
                        "id": str(insight_id),
                        "user_id": str(user_id),
                        "title": insight_data.title,
                        "description": insight_data.description,
                        "url": insight_data.url,
                        "image_url": insight_data.image_url,
                        "tags": []
                    }
                }
            
        except Exception as e:
            logger.error(f"åˆ›å»ºinsightå¤±è´¥: {str(e)}")
            return {"success": False, "message": f"åˆ›å»ºinsightå¤±è´¥: {str(e)}"}

    @staticmethod
    async def _fetch_and_save_content(insight_id: UUID, user_id: UUID, url: str, thought: Optional[str] = None) -> None:
        """å®Œæ•´çš„ insight å†…å®¹å¤„ç† pipelineï¼ˆå¼‚æ­¥åå°ä»»åŠ¡ï¼‰ã€‚

        æµç¨‹ï¼š
        1. æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰æ‘˜è¦
        2. å¦‚æœæ²¡æœ‰ï¼ŒæŠ“å–é¡µé¢å†…å®¹
        3. ç”Ÿæˆæ‘˜è¦ï¼ˆå¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼‰
        4. ä¿å­˜åˆ° insight_contents è¡¨
        5. æ›´æ–°ç¼“å­˜çŠ¶æ€

        ä½œä¸ºåå°ä»»åŠ¡è¿è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹ã€‚æ‰€æœ‰é”™è¯¯ä»…è®°å½•æ—¥å¿—ã€‚
        """
        try:
            logger.info(f"[åå°ä»»åŠ¡] å¼€å§‹å¤„ç† insight å†…å®¹: insight_id={insight_id}, url={url}")
            
            # 1. æŠ“å–é¡µé¢å†…å®¹ï¼ˆå…ˆæŠ“é¡µé¢ï¼Œå†æ ¹æ®é¡µé¢å†…å®¹ç”Ÿæˆæ‘˜è¦ï¼‰
            page = await fetch_page_content(url)
            logger.info(
                f"[åå°ä»»åŠ¡] æŠ“å–é¡µé¢å†…å®¹å®Œæˆï¼šstatus={page.get('status_code')}, ct={page.get('content_type')},"
                f" html={'Y' if page.get('html') else 'N'}, text_len={len(page.get('text') or '')},"
                f" blocked={page.get('blocked_reason')}"
            )

            # 2. æ¸…ç†æ–‡æœ¬ï¼ˆæ ‡å‡†åŒ–ã€å‹ç¼©ç©ºç™½ã€é•¿åº¦é™åˆ¶ï¼‰
            raw_text = page.get('text') or ''
            if not raw_text:
                try:
                    desc_res = (
                        get_supabase_service()
                        .table('insights')
                        .select('description')
                        .eq('id', str(insight_id))
                        .single()
                        .execute()
                    )
                    if getattr(desc_res, 'data', None):
                        raw_text = (desc_res.data.get('description') or '').strip()
                except Exception:
                    pass

            cleaned_text = raw_text.strip()
            if cleaned_text:
                # åªå‹ç¼©å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼Œä¿ç•™æ®µè½ç»“æ„
                cleaned_text = re.sub(r"[ \t]+", " ", cleaned_text)  # åªå‹ç¼©ç©ºæ ¼å’Œåˆ¶è¡¨ç¬¦
                cleaned_text = re.sub(r"\n\s*\n", "\n\n", cleaned_text)  # ä¿ç•™æ®µè½åˆ†éš”
                # Trafilatura å·²ç»åšäº†å¾ˆå¥½çš„å†…å®¹æå–å’Œé•¿åº¦æ§åˆ¶
            logger.info(f"[åå°ä»»åŠ¡] æ¸…ç†åæ–‡æœ¬é•¿åº¦: {len(cleaned_text) if cleaned_text else 0}")

            # 3. ç”Ÿæˆæ‘˜è¦ï¼ˆåŸºäºæ¸…ç†åçš„æ–‡æœ¬ï¼‰
            summary_text = None
            try:
                if cleaned_text:
                    logger.info(f"[åå°ä»»åŠ¡] å¼€å§‹ç”Ÿæˆæ‘˜è¦: {url}")
                    summary_text = await generate_summary(cleaned_text)
                    from app.routers.metadata import summary_cache
                    if summary_text:
                        logger.info(f"[åå°ä»»åŠ¡] ç”Ÿæˆæ‘˜è¦å®Œæˆ: {url}ï¼Œé•¿åº¦={len(summary_text)}")
                        summary_cache[url] = {
                            'status': 'completed',
                            'created_at': datetime.now(),
                            'summary': summary_text,
                            'error': None
                        }
                    else:
                        logger.warning("[åå°ä»»åŠ¡] ç”Ÿæˆæ‘˜è¦ä¸ºç©ºï¼Œæ ‡è®°ä¸ºå¤±è´¥")
                        summary_cache[url] = {
                            'status': 'failed',
                            'created_at': datetime.now(),
                            'summary': None,
                            'error': 'empty-summary'
                        }
            except Exception as _sum_err:
                from app.routers.metadata import summary_cache
                logger.warning(f"[åå°ä»»åŠ¡] æ‘˜è¦ç”Ÿæˆå¤±è´¥: {_sum_err}")
                summary_cache[url] = {
                    'status': 'failed',
                    'created_at': datetime.now(),
                    'summary': None,
                    'error': str(_sum_err)
                }

            # 4. å‡†å¤‡å†…å®¹æ•°æ®
            # 4. å‡†å¤‡å†…å®¹æ•°æ®ï¼ˆç»Ÿä¸€è§„èŒƒæ—¶é—´å­—æ®µä¸º ISO å­—ç¬¦ä¸²ï¼‰
            extracted_at_val = page.get('extracted_at')
            if isinstance(extracted_at_val, (datetime, date)):
                extracted_at_val = extracted_at_val.isoformat()
            # Sumy é¢„å¤„ç†å·²ç§»é™¤
            
            content_payload = {
                'insight_id': str(insight_id),
                'user_id': str(user_id),
                'url': url,
                'text': page.get('text'),  # Trafilatura æå–çš„å†…å®¹
                'markdown': page.get('markdown'),
                'content_type': page.get('content_type'),
                'extracted_at': extracted_at_val,
                'summary': summary_text,
                'thought': thought  # ä¿å­˜ç”¨æˆ·çš„æƒ³æ³•/å¤‡æ³¨åˆ°insight_contentsè¡¨
                # Sumy é¢„å¤„ç†å·²ç§»é™¤
            }

            # è®°å½•å¤„ç†ä¿¡æ¯
            try:
                logger.info(f"å³å°†å†™å…¥ insight_contents - summary é•¿åº¦: {len(summary_text) if summary_text else 0}, "
                          f"text é•¿åº¦: {len(page.get('text') or '')}")
                
                # Sumy é¢„å¤„ç†å·²ç§»é™¤ - ç›´æ¥ä½¿ç”¨ Trafilatura æå–çš„å†…å®¹
            except Exception:
                pass

            # 5. æ•°æ®æ¸…ç†
            def _sanitize_for_pg(obj: Any) -> Any:
                try:
                    if obj is None:
                        return None
                    if isinstance(obj, str):
                        return obj.replace('\x00', ' ').replace('\u0000', ' ')
                    if isinstance(obj, (datetime, date)):
                        return obj.isoformat()
                    if isinstance(obj, dict):
                        clean = {}
                        for k, v in obj.items():
                            clean[k] = _sanitize_for_pg(v)
                        return clean
                    if isinstance(obj, list):
                        return [_sanitize_for_pg(v) for v in obj]
                    return obj
                except Exception:
                    return obj

            safe_payload = _sanitize_for_pg(deepcopy(content_payload))

            # 6. ä¿å­˜åˆ°æ•°æ®åº“
            supabase_service = get_supabase_service()
            content_res = (
                supabase_service
                .table('insight_contents')
                .insert(safe_payload)
                .execute()
            )
            if hasattr(content_res, 'error') and content_res.error:
                logger.warning(f"[åå°ä»»åŠ¡] ä¿å­˜ insight_contents å¤±è´¥: {content_res.error}")
            else:
                logger.info(f"[åå°ä»»åŠ¡] insight_contents ä¿å­˜æˆåŠŸ: {url}")
                
                # 6.1 ä¿å­˜æ–‡æœ¬åˆ†å—æ•°æ®
                await _save_insight_chunks(insight_id, cleaned_text, page.get('refine_report', {}))
                
                # 6.2 ä¿å­˜åå›è¯»æ ¡éªŒï¼Œå¦‚ summary ä¸ºç©ºä¸”æˆ‘ä»¬æœ¬åœ°æœ‰ summary_textï¼Œåˆ™è¿›è¡Œä¸€æ¬¡å›å¡«æ›´æ–°
                try:
                    check_res = (
                        supabase_service
                        .table('insight_contents')
                        .select('id, summary')
                        .eq('insight_id', str(insight_id))
                        .order('created_at', desc=True)
                        .limit(1)
                        .execute()
                    )
                    row = check_res.data[0] if getattr(check_res, 'data', None) else None
                    db_summary = row.get('summary') if row else None
                    if summary_text and not db_summary and row and row.get('id'):
                        upd = (
                            supabase_service
                            .table('insight_contents')
                            .update({'summary': summary_text})
                            .eq('id', row['id'])
                            .execute()
                        )
                        if hasattr(upd, 'error') and upd.error:
                            logger.warning(f"[åå°ä»»åŠ¡] insight_contents å›å¡« summary å¤±è´¥: {upd.error}")
                        else:
                            logger.info("[åå°ä»»åŠ¡] insight_contents å›å¡« summary æˆåŠŸ")
                except Exception as verify_err:
                    logger.warning(f"[åå°ä»»åŠ¡] insight_contents å›è¯»/å›å¡«æ ¡éªŒå¤±è´¥: {verify_err}")
                
        except Exception as content_err:
            logger.error(f"[åå°ä»»åŠ¡] å†…å®¹å¤„ç†å¤±è´¥: {content_err}")
            # æ›´æ–°ç¼“å­˜çŠ¶æ€ä¸ºå¤±è´¥
            try:
                from app.routers.metadata import summary_cache
                summary_cache[url] = {
                    'status': 'failed',
                    'created_at': datetime.now(),
                    'summary': None,
                    'error': str(content_err)
                }
            except Exception:
                pass
        finally:
            logger.info(f"[åå°ä»»åŠ¡] å†…å®¹å¤„ç†ä»»åŠ¡ç»“æŸ: insight_id={insight_id}, url={url}")

    @staticmethod
    async def update_insight(insight_id: UUID, insight_data: InsightUpdate, user_id: UUID) -> Dict[str, Any]:
        """æ›´æ–°insight"""
        try:
            supabase = get_supabase()
            
            # æ£€æŸ¥insightæ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥ç”¨æˆ·
            existing_response = supabase.table('insights').select('user_id').eq('id', str(insight_id)).execute()
            
            if hasattr(existing_response, 'error') and existing_response.error:
                logger.error(f"æ£€æŸ¥insightå¤±è´¥: {existing_response.error}")
                return {"success": False, "message": "æ£€æŸ¥insightå¤±è´¥"}
            
            if not existing_response.data:
                return {"success": False, "message": "Insightä¸å­˜åœ¨"}
            
            if existing_response.data[0]['user_id'] != str(user_id):
                return {"success": False, "message": "æ— æƒæ›´æ–°æ­¤insight"}
            
            # å‡†å¤‡æ›´æ–°æ•°æ®ï¼ˆä¸åŒ…å«tagsï¼‰
            update_data = {}
            if insight_data.title is not None:
                update_data['title'] = insight_data.title
            if insight_data.description is not None:
                update_data['description'] = insight_data.description
            if insight_data.url is not None:
                update_data['url'] = insight_data.url
            if insight_data.image_url is not None:
                update_data['image_url'] = insight_data.image_url
            if insight_data.stack_id is not None:
                update_data['stack_id'] = insight_data.stack_id
            
            # æ›´æ–°insight
            if update_data:
                response = supabase.table('insights').update(update_data).eq('id', str(insight_id)).execute()
                
                if hasattr(response, 'error') and response.error:
                    logger.error(f"æ›´æ–°insightå¤±è´¥: {response.error}")
                    return {"success": False, "message": "æ›´æ–°insightå¤±è´¥"}
            
            # å¤„ç†thoughtå­—æ®µæ›´æ–°ï¼ˆç°åœ¨åœ¨insight_contentsè¡¨ä¸­ï¼‰
            if insight_data.thought is not None:
                try:
                    # æŸ¥æ‰¾ç°æœ‰çš„insight_contentsè®°å½•
                    supabase_service = get_supabase_service()
                    content_response = supabase_service.table('insight_contents').select('id').eq('insight_id', str(insight_id)).order('created_at', desc=True).limit(1).execute()
                    
                    if content_response.data:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        content_id = content_response.data[0]['id']
                        update_content_res = supabase_service.table('insight_contents').update({'thought': insight_data.thought}).eq('id', content_id).execute()
                        if hasattr(update_content_res, 'error') and update_content_res.error:
                            logger.warning(f"æ›´æ–°insight_contents.thoughtå¤±è´¥: {update_content_res.error}")
                        else:
                            logger.info(f"æˆåŠŸæ›´æ–°insight_contents.thought: insight_id={insight_id}")
                    else:
                        # å¦‚æœæ²¡æœ‰insight_contentsè®°å½•ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€è®°å½•
                        content_payload = {
                            'insight_id': str(insight_id),
                            'user_id': str(user_id),
                            'url': update_data.get('url', ''),  # ä½¿ç”¨æ›´æ–°çš„URLæˆ–ç©ºå­—ç¬¦ä¸²
                            'thought': insight_data.thought
                        }
                        create_content_res = supabase_service.table('insight_contents').insert(content_payload).execute()
                        if hasattr(create_content_res, 'error') and create_content_res.error:
                            logger.warning(f"åˆ›å»ºinsight_contentsè®°å½•å¤±è´¥: {create_content_res.error}")
                        else:
                            logger.info(f"æˆåŠŸåˆ›å»ºinsight_contentsè®°å½•: insight_id={insight_id}")
                except Exception as thought_err:
                    logger.warning(f"å¤„ç†thoughtå­—æ®µæ›´æ–°å¤±è´¥: {thought_err}")
            
            # å¤„ç†æ ‡ç­¾æ›´æ–°
            if insight_data.tag_ids is not None:
                tags_result = await InsightTagService.update_insight_tags_by_ids(
                    insight_id, insight_data.tag_ids, user_id
                )
                if not tags_result.get('success'):
                    logger.warning(f"æ›´æ–°insightæˆåŠŸï¼Œä½†æ ‡ç­¾å¤„ç†å¤±è´¥: {tags_result.get('message')}")
            
            # è·å–æ›´æ–°åçš„insightæ•°æ®
            return await InsightsService.get_insight(insight_id, user_id)
            
        except Exception as e:
            logger.error(f"æ›´æ–°insightå¤±è´¥: {str(e)}")
            return {"success": False, "message": f"æ›´æ–°insightå¤±è´¥: {str(e)}"}
    
    @staticmethod
    async def delete_insight(insight_id: UUID, user_id: UUID) -> Dict[str, Any]:
        """åˆ é™¤insight"""
        try:
            supabase = get_supabase()
            
            # æ£€æŸ¥insightæ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥ç”¨æˆ·
            existing_response = supabase.table('insights').select('user_id').eq('id', str(insight_id)).execute()
            
            if hasattr(existing_response, 'error') and existing_response.error:
                logger.error(f"æ£€æŸ¥insightå¤±è´¥: {existing_response.error}")
                return {"success": False, "message": "æ£€æŸ¥insightå¤±è´¥"}
            
            if not existing_response.data:
                return {"success": False, "message": "Insightä¸å­˜åœ¨"}
            
            if existing_response.data[0]['user_id'] != str(user_id):
                return {"success": False, "message": "æ— æƒåˆ é™¤æ­¤insight"}
            
            # åˆ é™¤insightï¼ˆæ ‡ç­¾å…³è”ä¼šé€šè¿‡CASCADEè‡ªåŠ¨åˆ é™¤ï¼‰
            response = supabase.table('insights').delete().eq('id', str(insight_id)).execute()
            
            if hasattr(response, 'error') and response.error:
                logger.error(f"åˆ é™¤insightå¤±è´¥: {response.error}")
                return {"success": False, "message": "åˆ é™¤insightå¤±è´¥"}
            
            return {"success": True, "message": "Insightåˆ é™¤æˆåŠŸ"}
            
        except Exception as e:
            logger.error(f"åˆ é™¤insightå¤±è´¥: {str(e)}")
            return {"success": False, "message": f"åˆ é™¤insightå¤±è´¥: {str(e)}"}


def _generate_etag(insights: list) -> str:
    """ç”Ÿæˆæ•°æ®çš„ ETag æŒ‡çº¹"""
    try:
        # åˆ›å»ºæ•°æ®æŒ‡çº¹ï¼šåŸºäº ID å’Œæ›´æ–°æ—¶é—´
        fingerprint_data = []
        for insight in insights:
            fingerprint_data.append({
                'id': insight.get('id'),
                'updated_at': insight.get('updated_at')
            })
        
        # ç”Ÿæˆ MD5 å“ˆå¸Œ
        data_str = json.dumps(fingerprint_data, sort_keys=True, default=str)
        return hashlib.md5(data_str.encode()).hexdigest()
    except Exception:
        # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºäºæ—¶é—´çš„ç®€å•å“ˆå¸Œ
        return hashlib.md5(str(datetime.utcnow()).encode()).hexdigest()


async def _save_insight_chunks(insight_id: UUID, text: str, refine_report: Dict[str, Any]) -> None:
    """ä¿å­˜ insight çš„æ–‡æœ¬åˆ†å—æ•°æ®"""
    try:
        if not text or not text.strip():
            logger.warning(f"[åˆ†å—ä¿å­˜] æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡åˆ†å—ä¿å­˜: insight_id={insight_id}")
            return
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†å—
        from app.utils.metadata import is_chunker_enabled, get_chunker_config
        if not is_chunker_enabled():
            logger.info(f"[åˆ†å—ä¿å­˜] åˆ†å—åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡åˆ†å—ä¿å­˜: insight_id={insight_id}")
            return
        
        # è·å–åˆ†å—é…ç½®
        config = get_chunker_config()
        
        # æ‰§è¡Œæ–‡æœ¬åˆ†å—
        from app.utils.text_chunker import chunk_text_for_llm
        chunk_result = chunk_text_for_llm(
            text=text,
            max_tokens=config['max_tokens'],
            chunk_size=config['chunk_size'],
            chunk_overlap=config['chunk_overlap'],
            method=config['method']
        )
        
        chunks = chunk_result.get('chunks', [])
        if not chunks:
            logger.warning(f"[åˆ†å—ä¿å­˜] æœªç”Ÿæˆåˆ†å—ï¼Œè·³è¿‡ä¿å­˜: insight_id={insight_id}")
            return
        
        logger.info(f"[åˆ†å—ä¿å­˜] å¼€å§‹ä¿å­˜åˆ†å—æ•°æ®: insight_id={insight_id}, åˆ†å—æ•°={len(chunks)}")
        
        # ç”Ÿæˆ embeddingï¼ˆå¦‚æœå¯ç”¨ï¼‰
        chunk_embeddings = []
        if is_embedding_enabled():
            try:
                logger.info(f"[åˆ†å—ä¿å­˜] å¼€å§‹ç”Ÿæˆ embedding: insight_id={insight_id}")
                chunk_embeddings = await generate_chunk_embeddings(chunks)
                logger.info(f"[åˆ†å—ä¿å­˜] æˆåŠŸç”Ÿæˆ {len(chunk_embeddings)} ä¸ª embedding")
            except Exception as e:
                logger.error(f"[åˆ†å—ä¿å­˜] ç”Ÿæˆ embedding å¤±è´¥: {e}")
                chunk_embeddings = []
        
        # å‡†å¤‡åˆ†å—æ•°æ®
        chunk_data = []
        for i, chunk_text in enumerate(chunks):
            chunk_item = {
                'insight_id': str(insight_id),
                'chunk_index': i,
                'chunk_text': chunk_text,
                'chunk_size': len(chunk_text),
                'estimated_tokens': chunk_result.get('estimated_tokens_per_chunk', 0),
                'chunk_method': chunk_result.get('method', config['method']),
                'chunk_overlap': config['chunk_overlap']
            }
            
            # æ·»åŠ  embedding æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if i < len(chunk_embeddings) and chunk_embeddings[i]:
                embedding_data = chunk_embeddings[i]
                embedding_vector = embedding_data.get('embedding')
                
                # ç¡®ä¿embeddingä»¥vector(1536)æ ¼å¼å­˜å‚¨
                if embedding_vector and len(embedding_vector) == 1536:
                    # å°†embeddingè½¬æ¢ä¸ºPostgreSQL vectoræ ¼å¼
                    # Supabase Pythonå®¢æˆ·ç«¯ä¼šè‡ªåŠ¨å¤„ç†vectorç±»å‹è½¬æ¢
                    chunk_item.update({
                        'embedding': embedding_vector,  # ç›´æ¥ä¼ é€’åˆ—è¡¨ï¼ŒSupabaseä¼šè½¬æ¢ä¸ºvector(1536)
                        'embedding_model': embedding_data.get('model'),
                        'embedding_tokens': embedding_data.get('tokens_used', 0),
                        'embedding_generated_at': embedding_data.get('generated_at')
                    })
                else:
                    logger.warning(f"[åˆ†å—ä¿å­˜] embeddingç»´åº¦ä¸æ­£ç¡®: {len(embedding_vector) if embedding_vector else 0}, æœŸæœ›1536")
            
            chunk_data.append(chunk_item)
        
        # å…ˆåˆ é™¤ç°æœ‰çš„åˆ†å—æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
        supabase_service = get_supabase_service()
        delete_res = (
            supabase_service
            .table('insight_chunks')
            .delete()
            .eq('insight_id', str(insight_id))
            .execute()
        )
        
        if hasattr(delete_res, 'error') and delete_res.error:
            logger.warning(f"[åˆ†å—ä¿å­˜] åˆ é™¤æ—§åˆ†å—æ•°æ®å¤±è´¥: {delete_res.error}")
        
        # æ•°æ®æ¸…ç†ï¼ˆç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®ï¼‰
        def _sanitize_chunk_data(obj: Any) -> Any:
            try:
                if obj is None:
                    return None
                if isinstance(obj, str):
                    return obj.replace('\x00', ' ').replace('\u0000', ' ')
                if isinstance(obj, (datetime, date)):
                    return obj.isoformat()
                if isinstance(obj, dict):
                    clean = {}
                    for k, v in obj.items():
                        clean[k] = _sanitize_chunk_data(v)
                    return clean
                if isinstance(obj, list):
                    return [_sanitize_chunk_data(v) for v in obj]
                return obj
            except Exception:
                return obj

        safe_chunk_data = _sanitize_chunk_data(deepcopy(chunk_data))
        
        # æ‰¹é‡æ’å…¥æ–°åˆ†å—æ•°æ®
        insert_res = (
            supabase_service
            .table('insight_chunks')
            .insert(safe_chunk_data)
            .execute()
        )
        
        if hasattr(insert_res, 'error') and insert_res.error:
            logger.error(f"[åˆ†å—ä¿å­˜] ä¿å­˜åˆ†å—æ•°æ®å¤±è´¥: {insert_res.error}")
        else:
            logger.info(f"[åˆ†å—ä¿å­˜] åˆ†å—æ•°æ®ä¿å­˜æˆåŠŸ: insight_id={insight_id}, åˆ†å—æ•°={len(chunks)}")
            
    except Exception as e:
        logger.error(f"[åˆ†å—ä¿å­˜] åˆ†å—ä¿å­˜å¼‚å¸¸: insight_id={insight_id}, error={e}")


