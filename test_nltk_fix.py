#!/usr/bin/env python3
"""
æµ‹è¯• NLTK æ•°æ®ä¸‹è½½ä¿®å¤
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_nltk_data():
    """æµ‹è¯• NLTK æ•°æ®æ˜¯å¦æ­£ç¡®ä¸‹è½½"""
    print("ğŸ§ª æµ‹è¯• NLTK æ•°æ®ä¸‹è½½...")
    
    try:
        import nltk
        
        # æ£€æŸ¥ punkt
        try:
            nltk.data.find('tokenizers/punkt')
            print("âœ… punkt æ•°æ®å·²å­˜åœ¨")
        except LookupError:
            print("ğŸ“¥ ä¸‹è½½ punkt æ•°æ®...")
            nltk.download('punkt', quiet=True)
            print("âœ… punkt æ•°æ®ä¸‹è½½å®Œæˆ")
        
        # æ£€æŸ¥ punkt_tab
        try:
            nltk.data.find('tokenizers/punkt_tab')
            print("âœ… punkt_tab æ•°æ®å·²å­˜åœ¨")
        except LookupError:
            print("ğŸ“¥ ä¸‹è½½ punkt_tab æ•°æ®...")
            nltk.download('punkt_tab', quiet=True)
            print("âœ… punkt_tab æ•°æ®ä¸‹è½½å®Œæˆ")
        
        # æ£€æŸ¥ stopwords
        try:
            nltk.data.find('corpora/stopwords')
            print("âœ… stopwords æ•°æ®å·²å­˜åœ¨")
        except LookupError:
            print("ğŸ“¥ ä¸‹è½½ stopwords æ•°æ®...")
            nltk.download('stopwords', quiet=True)
            print("âœ… stopwords æ•°æ®ä¸‹è½½å®Œæˆ")
        
        print("\nğŸ‰ æ‰€æœ‰ NLTK æ•°æ®æ£€æŸ¥å®Œæˆï¼")
        
        # æµ‹è¯• Sumy æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
        print("\nğŸ§ª æµ‹è¯• Sumy åŠŸèƒ½...")
        try:
            from app.utils.sumy_summarizer import extract_key_content_with_sumy
            
            test_text = """
            This is a test document. It contains multiple sentences.
            The second sentence provides more information.
            The third sentence adds additional context.
            This sentence is important for understanding the topic.
            Finally, this sentence concludes the test document.
            """
            
            result = extract_key_content_with_sumy(test_text)
            print(f"âœ… Sumy æµ‹è¯•æˆåŠŸï¼æå–äº† {len(result.get('key_sentences', []))} ä¸ªå…³é”®å¥")
            print(f"ğŸ“Š å‹ç¼©ç‡: {result.get('compression_ratio', 0):.1%}")
            
        except Exception as e:
            print(f"âŒ Sumy æµ‹è¯•å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ NLTK æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_nltk_data()
